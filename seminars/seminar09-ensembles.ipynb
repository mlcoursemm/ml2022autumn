{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Курс \"Машинное обучение\"\n",
    "\n",
    "## Тема занятия: Ансамбли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "print('Train: ', trainX.shape, trainY.shape, 'Test: ', testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Y labels: ', testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим (разные) классификаторы для ансамбля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsfrs = [\n",
    "    ('dtr', DecisionTreeClassifier(random_state=42)),\n",
    "    ('prc', Perceptron(random_state=42)),\n",
    "    ('svm', LinearSVC(random_state=42)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим стэкинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = StackingClassifier(estimators=clsfrs, final_estimator=LogisticRegression(random_state=42), n_jobs=-1)\n",
    "st.fit(trainX, trainY)\n",
    "print('Stacking (dtr, prc, svm) score:', st.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим (похожие) классификаторы для ансамбля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsfrs = [\n",
    "    ('svm1', LinearSVC(random_state=421)),\n",
    "    ('svm2', LinearSVC(random_state=422)),\n",
    "    ('svm3', LinearSVC(random_state=423)),\n",
    "]\n",
    "st = StackingClassifier(estimators=clsfrs, final_estimator=LogisticRegression(random_state=42), n_jobs=-1)\n",
    "st.fit(trainX, trainY)\n",
    "print('Stacking (svm1, svm2, svm3) score:', st.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsfrs = [\n",
    "    ('dtr1', DecisionTreeClassifier(random_state=421)),\n",
    "    ('dtr2', DecisionTreeClassifier(random_state=422)),\n",
    "    ('dtr3', DecisionTreeClassifier(random_state=423)),\n",
    "]\n",
    "st = StackingClassifier(estimators=clsfrs, final_estimator=LogisticRegression(random_state=42), n_jobs=-1)\n",
    "st.fit(trainX, trainY)\n",
    "print('Stacking (dtr1, dtr2, dtr3) score:', st.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsfrs = [\n",
    "    ('prc1', Perceptron(random_state=421)),\n",
    "    ('prc2', Perceptron(random_state=422)),\n",
    "    ('prc3', Perceptron(random_state=423)),\n",
    "]\n",
    "st = StackingClassifier(estimators=clsfrs, final_estimator=LogisticRegression(random_state=42), n_jobs=-1)\n",
    "st.fit(trainX, trainY)\n",
    "print('Stacking (prc1, prc2, prc3) score:', st.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовим классификаторы (деревья) для бэггинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(base_estimator=None, n_estimators=2, n_jobs=-1, random_state=42)\n",
    "bg.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_y = bg.predict(testX) # предсказываем классы\n",
    "print(out_y)\n",
    "out_score = bg.score(testX, testY) # считаем качество классификации\n",
    "print('Bagging (2 tree) score:', out_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Играемся с числом базовых классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(base_estimator=None, n_estimators=10, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('Bagging (10 tree) score:', bg.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(base_estimator=None, n_estimators=100, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('Bagging (100 tree) score:', bg.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поменяем базовые классификаторы на SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(base_estimator=clf, n_estimators=10, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('Bagging (10 svm) score:', bg.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(base_estimator=clf, n_estimators=100, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('Bagging (100 svm) score:', bg.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поработаем с деревьями в качестве базовых классификаторов для AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=None, n_estimators=10, random_state=42).fit(trainX, trainY)\n",
    "print('AdaBoost (10 tree) score:', ada.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на историю обучения (как добавление базовых классификаторов улучшает ситуацию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hist = list(ada.staged_score(testX, testY)) # посмотрим на историю обучения\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "plt.plot(s_hist)\n",
    "plt.xlabel('Boosting iteration')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим число деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=None, n_estimators=100, random_state=42).fit(trainX, trainY)\n",
    "print('AdaBoost (100 tree) score:', ada.score(testX, testY))\n",
    "print(\"Overfit!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пеменяем базовые классификаторы на логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=clf, n_estimators=10, random_state=42).fit(trainX, trainY)\n",
    "print('AdaBoost (10 logr) score:', ada.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=clf, n_estimators=100, random_state=42).fit(trainX, trainY)\n",
    "print('AdaBoost (100 logr) score:', ada.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=clf, n_estimators=1000, random_state=42).fit(trainX, trainY)\n",
    "print('AdaBoost (1000 logr) score:', ada.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг общего вида (на деревьях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=10, random_state=42).fit(trainX, trainY)\n",
    "print('Gradient Boosting (10 tree) score:', gb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, random_state=42).fit(trainX, trainY)\n",
    "print('Gradient Boosting (100 tree) score:', gb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим на сторонние успешные реализации, которые можно поставить с помощью:\n",
    "* pip/conda install xgboost\n",
    "* pip/conda install lightgbm\n",
    "* pip/conda install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.1, n_estimators=10, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('XGB (10 tree) score:', xgb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.1, n_estimators=100, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('XGB (100 tree) score:', xgb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.1, n_estimators=1000, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('XGB (1000 tree) score:', xgb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = LGBMClassifier(learning_rate=0.1, n_estimators=10, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('LGB (10 tree) score:', xgb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = LGBMClassifier(learning_rate=0.1, n_estimators=100, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('LGB (100 tree) score:', xgb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = LGBMClassifier(learning_rate=0.1, n_estimators=1000, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('LGB (1000 tree) score:', xgb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = LGBMClassifier(learning_rate=0.1, n_estimators=10000, n_jobs=-1, random_state=42).fit(trainX, trainY)\n",
    "print('LGB (2000 tree) score:', xgb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(learning_rate=0.1, n_estimators=10, thread_count=-1, random_state=42, logging_level='Silent').fit(trainX, trainY)\n",
    "print('CB (10 tree) score:', cb.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(learning_rate=0.1, n_estimators=100, thread_count=-1, random_state=42, logging_level='Silent').fit(trainX, trainY)\n",
    "print('CB (100 tree) score:', cb.score(testX, testY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
